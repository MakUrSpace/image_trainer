{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a213504-f9e9-4122-b1dc-5abf2637fbb3",
   "metadata": {},
   "source": [
    "# Image Object Recognition Trainer\n",
    "\n",
    "## Stage 1: Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21125801-faf1-425f-b8fc-a87886452950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6640dc4-8d23-46a4-8458-7c908873c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = \"./training_data\"\n",
    "image_width = 1080\n",
    "image_height = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d47f253-926b-455c-9642-de59e93d95e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [f for f in os.listdir(training_data) if f[-4:] == \".jpg\"]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d405a830-7e83-4c20-934c-4952acf0476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_daylight(image, brightness_threshold=100, blue_threshold=30):\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Extract the Value (brightness) channel\n",
    "    brightness = hsv[:, :, 2]\n",
    "\n",
    "    # Calculate average brightness\n",
    "    avg_brightness = np.mean(brightness)\n",
    "\n",
    "    # Convert to RGB and calculate average blue intensity\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    blue_channel = rgb[:, :, 2]\n",
    "    avg_blue_intensity = np.mean(blue_channel)\n",
    "\n",
    "    # Determine daylight\n",
    "    is_day = avg_brightness > brightness_threshold and avg_blue_intensity > blue_threshold\n",
    "\n",
    "    return is_day, avg_brightness, avg_blue_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9aacfee-f749-4117-a13b-8dc9ce6c391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import FileResponse, StreamingResponse, Response\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "annotations = []\n",
    "annotation_index = 1500\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Annotation:\n",
    "    coords: dict[str, tuple[int, int]]\n",
    "    value: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.value == \"\":\n",
    "            self.value = \"0\"\n",
    "\n",
    "\n",
    "def genDiceCam():\n",
    "    global captures, lastCaptureTime\n",
    "    while True:\n",
    "        orig = cc.capture()['Dice']\n",
    "        camImage = orig.copy()\n",
    "        cv2.putText(camImage, f'Capturing: {captureInProgress}',\n",
    "            (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        annotationStr = \"\"\n",
    "        for a in annotations:\n",
    "            coords = json.loads(a['coords'])\n",
    "            sp = [int(d) for d in coords['p0']]\n",
    "            ep = [int(d) for d in coords['p1']]\n",
    "            if captureInProgress:\n",
    "                value = a['value']\n",
    "                w, h = [d1 - d0 for d1, d0 in zip(ep, sp)]\n",
    "                annotationStr += f\"{value} {sp[0]} {sp[1]} {w} {h}\\n\"\n",
    "            cv2.rectangle(camImage, sp, ep, (0, 255, 100), 3)\n",
    "        ret, camImage = cv2.imencode('.jpg', camImage)\n",
    "\n",
    "        if captureInProgress and (lastCaptureTime is None or (datetime.utcnow() - lastCaptureTime).total_seconds() > 30):\n",
    "            imageName = f\"diceCollector_Cap{datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "            cv2.imwrite(f\"captures/{imageName}.jpg\", orig)\n",
    "            with open(f\"captures/{imageName}.txt\", \"w\") as f:\n",
    "                f.write(annotationStr)\n",
    "            lastCaptureTime = datetime.utcnow()\n",
    "            \n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpg\\r\\n\\r\\n' + camImage.tobytes() + b'\\r\\n')\n",
    "\n",
    "\n",
    "@app.get('/htmx.min.js')\n",
    "async def getHTMX():\n",
    "    return FileResponse(\"webapp_templates/htmx.min.js\", media_type=\"application/javascript\")\n",
    "\n",
    "\n",
    "@app.get('/bootstrap.min.js')\n",
    "async def getBootstrapJS():\n",
    "    return FileResponse(\"webapp_templates/bootstrap.min.js\", media_type=\"application/javascript\")\n",
    "\n",
    "\n",
    "@app.get('/bootstrap.min.css')\n",
    "async def getBootstrapCSS():\n",
    "    return FileResponse(\"webapp_templates/bootstrap.min.css\", media_type=\"text/css\")\n",
    "\n",
    "\n",
    "@app.get('/')\n",
    "async def getImageAnnotator():\n",
    "    read_annotations(images[annotation_index])\n",
    "    return FileResponse(\"webapp_templates/image_annotator.html\", media_type=\"text/html\")\n",
    "\n",
    "\n",
    "@app.get('/annotator')\n",
    "async def getImageAnnotator():\n",
    "    return FileResponse(\"webapp_templates/annotator.html\", media_type=\"text/html\", headers={\"Expires\": \"0\"})\n",
    "\n",
    "\n",
    "def render_annotations():\n",
    "    with open(\"webapp_templates/annotation.html\") as f:\n",
    "        template = f.read()\n",
    "    return \"\\n\".join([template.format(\n",
    "        annotation_index=idx,\n",
    "        annotation_coordinates=json.dumps(annotation.coords),\n",
    "        annotation_value=annotation.value)\n",
    "    for idx, annotation in enumerate(annotations)])\n",
    "\n",
    "\n",
    "def write_annotations(image_path):\n",
    "    image_annotation_path = f\"{training_data}/{image_path[:-4]}.txt\"\n",
    "    image_annotations = []\n",
    "    for annotation in annotations:\n",
    "        p0 = annotation.coords['p0']\n",
    "        p1 = annotation.coords['p1']\n",
    "        p0_x, p0_y = p0\n",
    "        p1_x, p1_y = p1\n",
    "        width, height = [abs(float(d1) - float(d0)) for d0, d1 in zip([p0_x, p0_y], [p1_x, p1_y])]\n",
    "        c_x = (float(p0_x) + width / 2) / image_width\n",
    "        c_y = (float(p0_y) + height / 2) / image_height\n",
    "        width /= image_width\n",
    "        height /= image_height\n",
    "        print(f\"Writing notation from {annotation.coords}: {c_x} {c_y} {width} {height}\")\n",
    "        image_annotations.append(f\"{annotation.value} {c_x} {c_y} {width} {height}\\n\")\n",
    "    with open(image_annotation_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(image_annotations))\n",
    "\n",
    "\n",
    "def read_annotations(image_path):\n",
    "    image_annotation_path = f\"{training_data}/{image_path[:-4]}.txt\"\n",
    "    global annotations\n",
    "    annotations = []\n",
    "    \n",
    "    if not os.path.exists(image_annotation_path):\n",
    "        return\n",
    "\n",
    "    with open(image_annotation_path) as f:\n",
    "        stored_image_annotations = f.read()\n",
    "    print(f\"Reading {stored_image_annotations}\")\n",
    "    for anno_line in stored_image_annotations.split(\"\\n\"):\n",
    "        try:\n",
    "            value, c_x, c_y, width, height = anno_line.split(\" \")\n",
    "        except:\n",
    "            continue\n",
    "        c_x = float(c_x)\n",
    "        c_y = float(c_y)\n",
    "        width = float(width)\n",
    "        height = float(height)\n",
    "        c_x *= image_width\n",
    "        c_y *= image_height\n",
    "        width *= image_width\n",
    "        height *= image_height\n",
    "        p0 = [c_x - width / 2, c_y - height / 2]\n",
    "        p1 = [c_x + width / 2, c_y + height / 2]\n",
    "        annotations.append(Annotation(coords={\"p0\": p0, \"p1\": p1}, value=value))\n",
    "\n",
    "\n",
    "@app.get(\"/annotation_index\")\n",
    "async def getAnnotationIndex():\n",
    "    return f\"{annotation_index} of {len(images) - 1}\"\n",
    "\n",
    "\n",
    "@app.post('/annotations')\n",
    "async def setAnnotations(request: Request):\n",
    "    # Path to your image file\n",
    "    raw_body = await request.body()  # Get the raw bytes of the request body\n",
    "    body_str = raw_body.decode(\"utf-8\")  # Decode bytes to a string\n",
    "    global annotations\n",
    "    annotations = [Annotation(**a) for a in json.loads(body_str)]  # Parse the JSON data\n",
    "    print(f\"Updated annotations: {annotations}\")\n",
    "    write_annotations(images[annotation_index])\n",
    "    return Response(render_annotations(), media_type=\"text/html\")\n",
    "\n",
    "\n",
    "@app.get('/annotations')\n",
    "async def getAnnotations(request: Request):\n",
    "    print(f\"Current annotations: {annotations}\")\n",
    "    return Response(render_annotations(), media_type=\"text/html\")\n",
    "\n",
    "\n",
    "@app.get('/clearannotations')\n",
    "async def clearAnnotations():\n",
    "    global captureInProgress, annotations\n",
    "    captureInProgress = False\n",
    "    annotations = []\n",
    "    return Response(\"Success!\", media_type=\"text/html\")\n",
    "\n",
    "@app.get(\"/image_list\")\n",
    "async def get_image_list():\n",
    "    rendered = \"\"\n",
    "    for idx, image in enumerate(images):\n",
    "        if idx == annotation_index:\n",
    "            image = f\"<b>{image}<b>\"\n",
    "        rendered = f\"{rendered}\\n{image}<br>\"\n",
    "    return Response(rendered, media_type=\"text/html\")\n",
    "\n",
    "\n",
    "def generate_image_stream():\n",
    "    while True:\n",
    "        image_name = images[annotation_index]\n",
    "        image_path = f\"training_data/{image_name}\"\n",
    "    \n",
    "        image = cv2.imread(image_path)\n",
    "        image_is_daylight, _, _ = is_daylight(image)\n",
    "        # label is_daylight\n",
    "        text = f\"Daylight: {image_is_daylight:5}\"\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 4\n",
    "        color = (255, 255, 255)  # White color in BGR\n",
    "        thickness = 2\n",
    "        \n",
    "        # Get the text size to calculate the position dynamically\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    \n",
    "        # Positions for different corners\n",
    "        top_left = (10, text_height + 20)  # Add some padding for clarity\n",
    "        \n",
    "        # Add text to each corner\n",
    "        cv2.putText(image, text, top_left, font, font_scale, color, thickness)\n",
    "\n",
    "        for annotation in annotations:\n",
    "            points = annotation.coords\n",
    "            # Convert points to integer tuples for OpenCV\n",
    "            p0 = tuple(map(int, points[\"p0\"]))\n",
    "            p1 = tuple(map(int, points[\"p1\"]))\n",
    "            \n",
    "            # Draw the rectangle\n",
    "            color = (0, 255, 0)  # Green color in BGR\n",
    "            thickness = 2        # Thickness of the rectangle border\n",
    "            cv2.rectangle(image, p0, p1, color, thickness)\n",
    "\n",
    "        # Encode the image as JPEG\n",
    "        _, img_encoded = cv2.imencode('.jpg', image)\n",
    "\n",
    "        # Yield the image bytes\n",
    "        yield (b\"--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n\" + img_encoded.tobytes() + b\"\\r\\n\")\n",
    "\n",
    "        # Wait before sending the next frame (simulate dynamic updates)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    \n",
    "@app.get(\"/image\")\n",
    "async def get_image():\n",
    "    return StreamingResponse(generate_image_stream(), media_type=\"multipart/x-mixed-replace; boundary=frame\")\n",
    "\n",
    "\n",
    "@app.get(\"/next\")\n",
    "async def next_image():\n",
    "    global annotation_index\n",
    "    annotation_index = min(len(images), annotation_index + 1)\n",
    "    print(f\"Updated annotation_index: {annotation_index}\")\n",
    "    read_annotations(images[annotation_index])\n",
    "    return FileResponse(\"webapp_templates/annotator.html\", media_type=\"text/html\", headers={\"Expires\": \"0\"})\n",
    "    \n",
    "@app.get(\"/prev\")\n",
    "async def prev_image():\n",
    "    global annotation_index\n",
    "    annotation_index = max(0, annotation_index - 1)\n",
    "    print(f\"Updated annotation_index: {annotation_index}\")\n",
    "    read_annotations(images[annotation_index])\n",
    "    return FileResponse(\"webapp_templates/annotator.html\", media_type=\"text/html\", headers={\"Expires\": \"0\"})\n",
    "    \n",
    "@app.get(\"/image/{idx}\")\n",
    "async def set_image(idx: int):\n",
    "    global annotation_index\n",
    "    annotation_index = min(len(images), max(0, idx))\n",
    "    print(f\"Updated annotation_index: {annotation_index}\")\n",
    "    read_annotations(images[annotation_index])\n",
    "    return FileResponse(\"webapp_templates/annotator.html\", media_type=\"text/html\", headers={\"Expires\": \"0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca49464d-8380-4ae5-987e-071205405590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [338071]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50258 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50258 - \"GET /bootstrap.min.js.map HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50274 - \"GET /bootstrap.min.css.map HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50258 - \"GET /annotator HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50258 - \"GET /image HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50274 - \"GET /annotation_index HTTP/1.1\" 200 OK\n",
      "Current annotations: []\n",
      "INFO:     127.0.0.1:50274 - \"GET /annotations HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50274 - \"GET /image_list HTTP/1.1\" 200 OK\n",
      "Updated annotations: [Annotation(coords={'p0': [1216.7441860465117, 864.3491379310345], 'p1': [1376.7441860465117, 990.9698275862069]}, value='0')]\n",
      "Writing notation from {'p0': [1216.7441860465117, 864.3491379310345], 'p1': [1376.7441860465117, 990.9698275862069]}: 1.2006890611541774 0.4831559806034483 0.14814814814814814 0.06594827586206892\n",
      "INFO:     127.0.0.1:50274 - \"POST /annotations HTTP/1.1\" 200 OK\n",
      "Updated annotation_index: 1501\n",
      "INFO:     127.0.0.1:50274 - \"GET /next HTTP/1.1\" 200 OK\n",
      "Current annotations: []\n",
      "INFO:     127.0.0.1:50274 - \"GET /annotations HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50284 - \"GET /annotation_index HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50288 - \"GET /image_list HTTP/1.1\" 200 OK\n",
      "Updated annotation_index: 1500\n",
      "INFO:     127.0.0.1:50288 - \"GET /prev HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50288 - \"GET /annotation_index HTTP/1.1\" 200 OK\n",
      "Current annotations: []\n",
      "INFO:     127.0.0.1:50284 - \"GET /annotations HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50274 - \"GET /image_list HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for connections to close. (CTRL+C to force quit)\n",
      "INFO:     Finished server process [338071]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3c37b-8672-45b4-b7e2-dcad055a7412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
